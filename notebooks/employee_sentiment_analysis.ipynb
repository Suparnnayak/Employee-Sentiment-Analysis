{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Employee Sentiment Analysis Project\n",
        "\n",
        "## Project Overview\n",
        "This notebook implements a comprehensive sentiment analysis system for employee messages. The project includes:\n",
        "1. **Sentiment Labeling**: Automatically label messages as Positive, Negative, or Neutral\n",
        "2. **Exploratory Data Analysis (EDA)**: Analyze and visualize data patterns\n",
        "3. **Employee Score Calculation**: Compute monthly sentiment scores\n",
        "4. **Employee Ranking**: Identify top positive and negative employees\n",
        "5. **Flight Risk Identification**: Detect employees at risk of leaving\n",
        "6. **Predictive Modeling**: Build linear regression model to predict sentiment scores\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import sys\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Add src directory to path\n",
        "# When running from notebooks/, src is at ../src\n",
        "notebook_dir = os.getcwd()\n",
        "project_root = os.path.dirname(notebook_dir)\n",
        "src_path = os.path.join(project_root, 'src')\n",
        "\n",
        "# Try multiple path options\n",
        "if os.path.exists(src_path):\n",
        "    sys.path.insert(0, src_path)\n",
        "elif os.path.exists(os.path.join('..', 'src')):\n",
        "    sys.path.insert(0, os.path.join('..', 'src'))\n",
        "else:\n",
        "    # Try absolute path from current location\n",
        "    abs_src = os.path.abspath(os.path.join('..', 'src'))\n",
        "    if os.path.exists(abs_src):\n",
        "        sys.path.insert(0, abs_src)\n",
        "\n",
        "# Import custom modules\n",
        "try:\n",
        "    from sentiment_labeling import SentimentLabeler\n",
        "    from eda import EDAAnalyzer\n",
        "    from scoring import EmployeeScorer\n",
        "    from flight_risk import FlightRiskAnalyzer\n",
        "    from modeling import SentimentPredictor\n",
        "    print(\"✓ Custom modules imported successfully\")\n",
        "except ImportError as e:\n",
        "    print(f\"✗ Error importing custom modules: {e}\")\n",
        "    print(f\"  Current directory: {os.getcwd()}\")\n",
        "    print(f\"  Tried src path: {src_path}\")\n",
        "    print(f\"  Python path: {sys.path}\")\n",
        "    raise\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('display.width', None)\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(\"✓ All libraries imported successfully!\")\n",
        "print(f\"  Working directory: {os.getcwd()}\")\n",
        "print(f\"  Source path: {src_path if os.path.exists(src_path) else 'Not found'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 1: Data Loading and Initial Exploration\n",
        "\n",
        "First, let's load the dataset and examine its structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "data_path = os.path.join('..', 'data', 'test.csv')\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(data_path)\n",
        "    print(f\"Dataset loaded successfully!\")\n",
        "    print(f\"Shape: {df.shape}\")\n",
        "    print(f\"\\nFirst few rows:\")\n",
        "    print(df.head())\n",
        "    print(f\"\\nColumn names: {df.columns.tolist()}\")\n",
        "    print(f\"\\nData types:\")\n",
        "    print(df.dtypes)\n",
        "    print(f\"\\nMissing values:\")\n",
        "    print(df.isnull().sum())\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: File not found at {data_path}\")\n",
        "    print(\"Please ensure test.csv is in the data/ directory\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading dataset: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 2: Sentiment Labeling\n",
        "\n",
        "**Objective**: Label each employee message with one of three sentiment categories: Positive, Negative, or Neutral.\n",
        "\n",
        "**Approach**: We'll use VADER (Valence Aware Dictionary and sEntiment Reasoner) sentiment analyzer, which is well-suited for social media text and short messages. VADER is fast, doesn't require training data, and works well with informal text.\n",
        "\n",
        "**Alternative**: We could also use transformer-based models (like RoBERTa) for potentially better accuracy, but VADER is faster and sufficient for this task.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize sentiment labeler\n",
        "# Using VADER for speed and efficiency\n",
        "# For better accuracy, you can use method='transformer' (requires GPU)\n",
        "labeler = SentimentLabeler(method='vader', use_gpu=False)\n",
        "\n",
        "# Label all messages\n",
        "df_labeled = labeler.label_dataframe(df, text_column='message')\n",
        "\n",
        "# Display results\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SENTIMENT LABELING RESULTS\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nTotal messages labeled: {len(df_labeled)}\")\n",
        "print(f\"\\nSentiment distribution:\")\n",
        "print(df_labeled['sentiment'].value_counts())\n",
        "print(f\"\\nSentiment percentages:\")\n",
        "print(df_labeled['sentiment'].value_counts(normalize=True) * 100)\n",
        "\n",
        "# Show sample labeled messages\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SAMPLE LABELED MESSAGES\")\n",
        "print(\"=\"*60)\n",
        "sample_df = df_labeled[['employee', 'date', 'message', 'sentiment']].head(10)\n",
        "print(sample_df.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 3: Exploratory Data Analysis (EDA)\n",
        "\n",
        "**Objective**: Understand the structure, distribution, and trends in the dataset through thorough exploration.\n",
        "\n",
        "**Key Areas of Analysis**:\n",
        "- Overall data structure and quality\n",
        "- Sentiment distribution across the dataset\n",
        "- Temporal trends (over time)\n",
        "- Employee activity patterns\n",
        "- Message characteristics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize EDA analyzer\n",
        "eda = EDAAnalyzer(df_labeled)\n",
        "\n",
        "# Basic dataset information\n",
        "print(\"=\"*60)\n",
        "print(\"EXPLORATORY DATA ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "basic_info = eda.basic_info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sentiment distribution visualization\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SENTIMENT DISTRIBUTION ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "sentiment_counts = eda.sentiment_distribution(\n",
        "    save_path=os.path.join('..', 'visualizations', 'sentiment_distribution.png')\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Temporal trends analysis\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TEMPORAL TRENDS ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "eda.temporal_trends(\n",
        "    save_path=os.path.join('..', 'visualizations', 'sentiment_trends.png')\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Employee activity analysis\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"EMPLOYEE ACTIVITY ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "eda.employee_activity(\n",
        "    top_n=10,\n",
        "    save_path=os.path.join('..', 'visualizations', 'employee_activity.png')\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Message length analysis\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MESSAGE LENGTH ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "eda.message_length_analysis(\n",
        "    save_path=os.path.join('..', 'visualizations', 'message_length_analysis.png')\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate comprehensive summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"EDA SUMMARY REPORT\")\n",
        "print(\"=\"*60)\n",
        "summary = eda.generate_summary_report()\n",
        "for key, value in summary.items():\n",
        "    print(f\"\\n{key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 4: Employee Score Calculation\n",
        "\n",
        "**Objective**: Compute a monthly sentiment score for each employee based on their messages.\n",
        "\n",
        "**Scoring System**:\n",
        "- Positive Message: +1\n",
        "- Negative Message: -1\n",
        "- Neutral Message: 0 (no effect)\n",
        "\n",
        "**Method**: Scores are aggregated on a monthly basis for each employee, resetting at the beginning of each new month.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize employee scorer\n",
        "scorer = EmployeeScorer(df_labeled)\n",
        "\n",
        "# Calculate monthly scores\n",
        "print(\"=\"*60)\n",
        "print(\"EMPLOYEE SCORE CALCULATION\")\n",
        "print(\"=\"*60)\n",
        "monthly_scores = scorer.calculate_scores()\n",
        "\n",
        "print(f\"\\nMonthly scores calculated for {len(monthly_scores)} employee-month combinations\")\n",
        "print(f\"\\nSample monthly scores:\")\n",
        "print(monthly_scores.head(20).to_string(index=False))\n",
        "\n",
        "print(f\"\\nScore statistics:\")\n",
        "print(monthly_scores['monthly_score'].describe())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display scores by employee\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MONTHLY SCORES BY EMPLOYEE\")\n",
        "print(\"=\"*60)\n",
        "employee_col = monthly_scores.columns[0]  # Get employee column name\n",
        "\n",
        "for employee in monthly_scores[employee_col].unique():\n",
        "    emp_scores = monthly_scores[monthly_scores[employee_col] == employee]\n",
        "    print(f\"\\n{employee}:\")\n",
        "    for _, row in emp_scores.iterrows():\n",
        "        print(f\"  {row['year_month']}: Score = {row['monthly_score']} \"\n",
        "              f\"(Messages: {row.get('message_count', 'N/A')}, \"\n",
        "              f\"Positive: {row.get('positive_count', 'N/A')}, \"\n",
        "              f\"Negative: {row.get('negative_count', 'N/A')})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 5: Employee Ranking\n",
        "\n",
        "**Objective**: Generate ranked lists of employees based on their monthly sentiment scores.\n",
        "\n",
        "**Requirements**:\n",
        "- Top Three Positive Employees: Highest positive scores per month\n",
        "- Top Three Negative Employees: Lowest (most negative) scores per month\n",
        "- Sorted in descending order by score, then alphabetically\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to get top employees per month\n",
        "def get_top_employees(monthly_scores, top_n=3, positive=True):\n",
        "    \"\"\"\n",
        "    Get top N employees per month based on sentiment scores\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    monthly_scores : pd.DataFrame\n",
        "        DataFrame with monthly scores\n",
        "    top_n : int\n",
        "        Number of top employees to return\n",
        "    positive : bool\n",
        "        If True, return top positive; if False, return top negative\n",
        "    \"\"\"\n",
        "    employee_col = monthly_scores.columns[0]\n",
        "    results = []\n",
        "    \n",
        "    for year_month in monthly_scores['year_month'].unique():\n",
        "        month_data = monthly_scores[monthly_scores['year_month'] == year_month].copy()\n",
        "        \n",
        "        if positive:\n",
        "            # Top positive (highest scores)\n",
        "            top_employees = month_data.nlargest(top_n, 'monthly_score')\n",
        "        else:\n",
        "            # Top negative (lowest scores)\n",
        "            top_employees = month_data.nsmallest(top_n, 'monthly_score')\n",
        "        \n",
        "        # Sort by score (descending) then alphabetically\n",
        "        top_employees = top_employees.sort_values(\n",
        "            ['monthly_score', employee_col], \n",
        "            ascending=[False, True]\n",
        "        )\n",
        "        \n",
        "        for _, row in top_employees.iterrows():\n",
        "            results.append({\n",
        "                'year_month': year_month,\n",
        "                employee_col: row[employee_col],\n",
        "                'monthly_score': row['monthly_score'],\n",
        "                'message_count': row.get('message_count', 'N/A'),\n",
        "                'positive_count': row.get('positive_count', 'N/A'),\n",
        "                'negative_count': row.get('negative_count', 'N/A')\n",
        "            })\n",
        "    \n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Get top positive employees\n",
        "print(\"=\"*60)\n",
        "print(\"TOP THREE POSITIVE EMPLOYEES BY MONTH\")\n",
        "print(\"=\"*60)\n",
        "top_positive = get_top_employees(monthly_scores, top_n=3, positive=True)\n",
        "print(top_positive.to_string(index=False))\n",
        "\n",
        "# Get top negative employees\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TOP THREE NEGATIVE EMPLOYEES BY MONTH\")\n",
        "print(\"=\"*60)\n",
        "top_negative = get_top_employees(monthly_scores, top_n=3, positive=False)\n",
        "print(top_negative.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize employee rankings\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Top positive employees visualization\n",
        "employee_col = monthly_scores.columns[0]\n",
        "for year_month in monthly_scores['year_month'].unique():\n",
        "    month_data = monthly_scores[monthly_scores['year_month'] == year_month]\n",
        "    top_pos = month_data.nlargest(3, 'monthly_score').sort_values(\n",
        "        ['monthly_score', employee_col], ascending=[False, True]\n",
        "    )\n",
        "    \n",
        "    if len(top_pos) > 0:\n",
        "        axes[0].barh(\n",
        "            range(len(top_pos)), \n",
        "            top_pos['monthly_score'].values,\n",
        "            label=str(year_month)\n",
        "        )\n",
        "\n",
        "axes[0].set_title('Top 3 Positive Employees by Month', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel('Monthly Score', fontsize=12)\n",
        "axes[0].set_ylabel('Rank', fontsize=12)\n",
        "axes[0].legend(title='Month', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "axes[0].grid(axis='x', alpha=0.3)\n",
        "\n",
        "# Top negative employees visualization\n",
        "for year_month in monthly_scores['year_month'].unique():\n",
        "    month_data = monthly_scores[monthly_scores['year_month'] == year_month]\n",
        "    top_neg = month_data.nsmallest(3, 'monthly_score').sort_values(\n",
        "        ['monthly_score', employee_col], ascending=[True, True]\n",
        "    )\n",
        "    \n",
        "    if len(top_neg) > 0:\n",
        "        axes[1].barh(\n",
        "            range(len(top_neg)), \n",
        "            top_neg['monthly_score'].values,\n",
        "            label=str(year_month)\n",
        "        )\n",
        "\n",
        "axes[1].set_title('Top 3 Negative Employees by Month', fontsize=14, fontweight='bold')\n",
        "axes[1].set_xlabel('Monthly Score', fontsize=12)\n",
        "axes[1].set_ylabel('Rank', fontsize=12)\n",
        "axes[1].legend(title='Month', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "axes[1].grid(axis='x', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\n",
        "    os.path.join('..', 'visualizations', 'employee_rankings.png'),\n",
        "    dpi=300,\n",
        "    bbox_inches='tight'\n",
        ")\n",
        "print(\"Ranking visualization saved!\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 6: Flight Risk Identification\n",
        "\n",
        "**Objective**: Identify employees who are at risk of leaving based on their monthly sentiment scores.\n",
        "\n",
        "**Criteria**: A Flight risk is any employee who has sent 4 or more negative messages in a rolling 30-day period (irrespective of months).\n",
        "\n",
        "**Method**: We use a rolling window approach to check for 30-day periods where an employee has 4+ negative messages.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize flight risk analyzer\n",
        "flight_risk_analyzer = FlightRiskAnalyzer(df_labeled)\n",
        "\n",
        "# Identify flight risks\n",
        "print(\"=\"*60)\n",
        "print(\"FLIGHT RISK IDENTIFICATION\")\n",
        "print(\"=\"*60)\n",
        "flight_risks = flight_risk_analyzer.identify_flight_risks(threshold=4, window_days=30)\n",
        "\n",
        "if len(flight_risks) > 0:\n",
        "    print(f\"\\nFound {len(flight_risks)} employee(s) at flight risk:\")\n",
        "    print(\"\\n\" + flight_risks.to_string(index=False))\n",
        "    \n",
        "    # Get summary\n",
        "    summary = flight_risk_analyzer.get_flight_risk_summary(threshold=4, window_days=30)\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"FLIGHT RISK SUMMARY\")\n",
        "    print(\"=\"*60)\n",
        "    for key, value in summary.items():\n",
        "        print(f\"{key}: {value}\")\n",
        "else:\n",
        "    print(\"\\nNo employees identified as flight risks.\")\n",
        "    print(\"(No employee has 4+ negative messages in a 30-day rolling window)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Store flight risk list for final report\n",
        "if len(flight_risks) > 0:\n",
        "    employee_col = flight_risks.columns[0]\n",
        "    flight_risk_employees = flight_risks[employee_col].tolist()\n",
        "    print(f\"\\nFlight Risk Employees List: {flight_risk_employees}\")\n",
        "else:\n",
        "    flight_risk_employees = []\n",
        "    print(\"\\nNo flight risk employees identified.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task 7: Predictive Modeling\n",
        "\n",
        "**Objective**: Develop a linear regression model to analyze sentiment trends and predict sentiment scores.\n",
        "\n",
        "**Features Used**:\n",
        "- Message frequency in a month\n",
        "- Average message length\n",
        "- Total message length\n",
        "- Average word count\n",
        "- Total word count\n",
        "- Positive/negative/neutral ratios\n",
        "- Month (temporal feature)\n",
        "\n",
        "**Evaluation**: We'll use train-test split and evaluate using MSE, RMSE, MAE, and R² metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize predictor\n",
        "predictor = SentimentPredictor(df_labeled, monthly_scores)\n",
        "\n",
        "# Build and train the model\n",
        "print(\"=\"*60)\n",
        "print(\"PREDICTIVE MODELING - LINEAR REGRESSION\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nBuilding model...\")\n",
        "metrics = predictor.build_model(test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MODEL PERFORMANCE METRICS\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nTraining Set Metrics:\")\n",
        "for metric, value in metrics['train'].items():\n",
        "    print(f\"  {metric.upper()}: {value:.4f}\")\n",
        "\n",
        "print(\"\\nTest Set Metrics:\")\n",
        "for metric, value in metrics['test'].items():\n",
        "    print(f\"  {metric.upper()}: {value:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FEATURE IMPORTANCE\")\n",
        "print(\"=\"*60)\n",
        "feature_importance = pd.Series(metrics['feature_importance']).sort_values(ascending=False)\n",
        "for feature, importance in feature_importance.items():\n",
        "    print(f\"  {feature}: {importance:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize model performance\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MODEL PERFORMANCE VISUALIZATION\")\n",
        "print(\"=\"*60)\n",
        "predictor.plot_model_performance(\n",
        "    save_path=os.path.join('..', 'visualizations', 'model_performance.png')\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get model summary\n",
        "model_summary = predictor.get_model_summary()\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MODEL SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Intercept: {model_summary['intercept']:.4f}\")\n",
        "print(f\"\\nNumber of features: {model_summary['n_features']}\")\n",
        "print(f\"Training samples: {model_summary['n_train_samples']}\")\n",
        "print(f\"Test samples: {model_summary['n_test_samples']}\")\n",
        "print(f\"\\nCoefficients:\")\n",
        "for feature, coef in model_summary['coefficients'].items():\n",
        "    print(f\"  {feature}: {coef:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary and Key Findings\n",
        "\n",
        "Let's compile the key findings from our analysis:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compile final summary\n",
        "print(\"=\"*60)\n",
        "print(\"FINAL PROJECT SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Top positive employees (overall)\n",
        "employee_col = monthly_scores.columns[0]\n",
        "overall_positive = monthly_scores.groupby(employee_col)['monthly_score'].sum().nlargest(3)\n",
        "print(\"\\nTop 3 Positive Employees (Overall):\")\n",
        "for i, (employee, score) in enumerate(overall_positive.items(), 1):\n",
        "    print(f\"  {i}. {employee}: {score}\")\n",
        "\n",
        "# Top negative employees (overall)\n",
        "overall_negative = monthly_scores.groupby(employee_col)['monthly_score'].sum().nsmallest(3)\n",
        "print(\"\\nTop 3 Negative Employees (Overall):\")\n",
        "for i, (employee, score) in enumerate(overall_negative.items(), 1):\n",
        "    print(f\"  {i}. {employee}: {score}\")\n",
        "\n",
        "# Flight risks\n",
        "print(f\"\\nFlight Risk Employees: {len(flight_risk_employees)}\")\n",
        "if len(flight_risk_employees) > 0:\n",
        "    for employee in flight_risk_employees:\n",
        "        print(f\"  - {employee}\")\n",
        "else:\n",
        "    print(\"  None identified\")\n",
        "\n",
        "# Model performance\n",
        "print(f\"\\nModel Performance (R² Score):\")\n",
        "print(f\"  Training: {metrics['train']['r2']:.4f}\")\n",
        "print(f\"  Test: {metrics['test']['r2']:.4f}\")\n",
        "\n",
        "# Sentiment distribution\n",
        "sentiment_dist = df_labeled['sentiment'].value_counts()\n",
        "print(f\"\\nOverall Sentiment Distribution:\")\n",
        "for sentiment, count in sentiment_dist.items():\n",
        "    pct = (count / len(df_labeled)) * 100\n",
        "    print(f\"  {sentiment}: {count} ({pct:.1f}%)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Analysis Complete!\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save processed data for reference\n",
        "output_path = os.path.join('..', 'data', 'processed_data.csv')\n",
        "df_labeled.to_csv(output_path, index=False)\n",
        "print(f\"Processed data saved to {output_path}\")\n",
        "\n",
        "# Save monthly scores\n",
        "scores_path = os.path.join('..', 'data', 'monthly_scores.csv')\n",
        "monthly_scores.to_csv(scores_path, index=False)\n",
        "print(f\"Monthly scores saved to {scores_path}\")\n",
        "\n",
        "# Save flight risks if any\n",
        "if len(flight_risks) > 0:\n",
        "    risks_path = os.path.join('..', 'data', 'flight_risks.csv')\n",
        "    flight_risks.to_csv(risks_path, index=False)\n",
        "    print(f\"Flight risks saved to {risks_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
